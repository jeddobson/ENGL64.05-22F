{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1>Cultural Analytics</h1><br>\n",
    "<h2>ENGL64.05 / QSS 30.16 22F</h2>\n",
    "</center>\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "# Lab 4\n",
    "\n",
    "This lab will help in learning how to plot data using matplotlib and Pandas.\n",
    "\n",
    "## Plotting Data!\n",
    "\n",
    " <center><pre>Created: 10/09/2019; Revised 10/05/2022</pre></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "|Count|Chest Size|\n",
    "|---|---|\n",
    "|3|33|\n",
    "|18|34|\n",
    "|81|35|\n",
    "|185|36|\n",
    "|420|37|\n",
    "|749|38|\n",
    "|1073|39|\n",
    "|1079|40|\n",
    "|934|41|\n",
    "|658|42|\n",
    "|370|43|\n",
    "|92|44|\n",
    "|50|45|\n",
    "|21|46|\n",
    "|4|47|\n",
    "|1|48|\n",
    "\n",
    "\n",
    "These are the chest measurements of 5,738 Scottish militiamen (and a classic dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1.1: Plotting Data with Matplotlib [Simple]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some generally useful packages\n",
    "import csv\n",
    "import numpy as np\n",
    "import nltk\n",
    "from glob import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first task will be to produce a graphic chart from the Scottish chest measurement dataset. Turn these values into data using what you think would be the best datatype to plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are needed to use the plotting tools and display within Jupyter\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# documentation and examples for using matplotlib can be found here:\n",
    "# https://matplotlib.org/stable/index.html\n",
    "# https://matplotlib.org/stable/plot_types/index.html\n",
    "# https://matplotlib.org/stable/tutorials/introductory/pyplot.html#sphx-glr-tutorials-introductory-pyplot-py\n",
    "\n",
    "# We can call matplotlib with some methods for different types of charts:\n",
    "# - scatter\n",
    "# - bar\n",
    "# - plot (line) \n",
    "# - pie \n",
    "#\n",
    "# These can be called from what we've imported as plt as follows:\n",
    "# plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the code need to display the above data \n",
    "# Make sure that you have:\n",
    "# a) a title\n",
    "# b) labels on the x and y axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's fetch some data....\n",
    "metadata = pd.read_csv(\"shared/ENGL64.05-22F/data/na-slave-narratives/data/toc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will give us a list of publication years available. The date\n",
    "# are a little messy in this file.\n",
    "\n",
    "publication_years = [int(d) for d in metadata['Date'] if str(d).isdigit()]\n",
    "\n",
    "\n",
    "## FIRST, let's plot these data with matplotlib.\n",
    "\n",
    "# We want to produce a chart showing the publication years of our texts \n",
    "# Our x axis should be year of publication\n",
    "# Our y axis should be the number of publications in this year \n",
    "# Produce this graphic with a title and labels\n",
    "\n",
    "# To resize the image, provide arguments for figsize. Something like the \n",
    "# following will work well for wide graphs/figures:\n",
    "# figsize=(20,5)\n",
    "\n",
    "# HINTS:\n",
    "# You can use set() to produce unique list of years\n",
    "# You can count repetitions in a list with the .count(item) method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW, let's create a Pandas DataFrame and create a similar plot. \n",
    "# You can plot by referencing the dataframe (\"df\") with the .plot method.\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html\n",
    "# You may want to use value_counts() instead of contents of the DataFrame\n",
    "\n",
    "df = pd.DataFrame(publication_years)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.2: A Quick Review of Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a list of punctuation types\n",
    "punctuation_list = [\".\",\",\",\";\",\":\",\"?\",\"!\",\"â€”\",\"-\",\"[\",\"(\",\"&\",\"/\"]\n",
    "\n",
    "# Use glob or another method to iterate through between 3-10 texts in Novel450 and \n",
    "# extract counts of the use of these punctuation marks within the entire text.\n",
    "\n",
    "# You'll want to define a list that will contain counts of these types in multiple texts\n",
    "# You can do this all in two loops: the outer loop iterating through the texts and the \n",
    "# inner loop iterating through the punctuation types.\n",
    "\n",
    "# Your goal is to create a list of lists called \"punct_data\" that looks something like this:\n",
    "# [[4787, 7144, 1079, 637, 686, 339, 0, 0, 1, 10, 0, 0],\n",
    "# [1512, 1939, 197, 156, 163, 106, 1, 0, 0, 1, 0, 0],\n",
    "# [4078, 6033, 1012, 551, 656, 283, 9, 0, 0, 134, 0, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll now convert this list-of-lists to a Pandas DataFrame:\n",
    "df = pd.DataFrame(punct_data,columns=punctuation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the contents of the dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create a boxplot from the dataframe. What does this show us?\n",
    "# https://en.wikipedia.org/wiki/Box_plot\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.boxplot.html\n",
    "#\n",
    "# You may want to resize the canvas with figsize=(20,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Advanced Plotting of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have this data to plot.\n",
    "# Create a line graph of these data using either matplotlib or Pandas.\n",
    "\n",
    "data_to_plot = [0.3956442831215971, 0.3351482153660012, 0.3660012099213551, 0.3647912885662432, \n",
    " 0.36721113127646704, 0.32425892316999394, 0.38052026618269813, 0.3841500302480339, \n",
    " 0.34966727162734423, 0.338777979431337, 0.29159104658197216, 0.3073200241984271, 0.3702359346642468,\n",
    " 0.3545069570477919, 0.37447065940713853, 0.3411978221415608, 0.3466424682395644, 0.31518451300665457,\n",
    " 0.3502722323049002, 0.35511191772534784, 0.3194192377495463, 0.36358136721113127, 0.33454325468844526,\n",
    " 0.36358136721113127, 0.32728372655777377, 0.3472474289171204, 0.3629764065335753, 0.3895946763460375,\n",
    " 0.33998790078644886, 0.33030852994555354, 0.3290986085904416, 0.33454325468844526, 0.36721113127646704,\n",
    " 0.34603750756200846, 0.2958257713248639, 0.30671506352087113, 0.32123411978221417, 0.3042952208106473,\n",
    " 0.32244404113732605, 0.3502722323049002, 0.36116152450090744, 0.3617664851784634, 0.35571687840290384,\n",
    " 0.3139745916515426, 0.33756805807622503, 0.37265577737447064, 0.33998790078644886, 0.3200241984271022,\n",
    " 0.3218390804597701, 0.3411978221415608, 0.32728372655777377, 0.32244404113732605, 0.29522081064730793,\n",
    " 0.3290986085904416, 0.34059286146400486, 0.35753176043557167, 0.3629764065335753, 0.3702359346642468,\n",
    " 0.3424077434966727, 0.37265577737447064, 0.37568058076225047, 0.37326073805202664, 0.35511191772534784,\n",
    " 0.3351482153660012, 0.3666061705989111, 0.3442226255293406, 0.37084089534180276, 0.37084089534180276,\n",
    " 0.32304900181488205, 0.3502722323049002, 0.33454325468844526, 0.382335148215366, 0.352692075015124,\n",
    " 0.3871748336358137, 0.3641863278886872, 0.37144585601935876, 0.3430127041742287, 0.33575317604355714,\n",
    " 0.3290986085904416, 0.3484573502722323, 0.32425892316999394, 0.31881427707199034, 0.34361766485178463,\n",
    " 0.3605565638233515, 0.33272837265577737, 0.3248638838475499, 0.3206291591046582, 0.3339382940108893,\n",
    " 0.3454325468844525, 0.32425892316999394, 0.3254688445251059, 0.35753176043557167, 0.33030852994555354,\n",
    " 0.31881427707199034, 0.3411978221415608, 0.338777979431337, 0.3297035692679976, 0.31518451300665457,\n",
    " 0.3514821536600121, 0.3412903225806452]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1: Smoothing and Regression\n",
    "\n",
    "There are a variety of ways in which we could examine trends in our data--especially with potentially noisy time series data. Smoothing applies a filter to enable us to present a line with fewer peaks and valleys. Abberant or outlier data are smoothed away with the filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can define a function to use signal processing filters with some preset\n",
    "# values that appear to work well for this sort of data. The following uses\n",
    "# a Savitzky-Golay filter from SciPy to process our data.\n",
    "\n",
    "from scipy import signal\n",
    "def smooth_sgf(raw):\n",
    "    wl = 21      # wl = window_length, the number of coeffiecents to use for the filter window\n",
    "    p = 3        # p = polyorder: the order of the polynomial used to fit our data \n",
    "    smoothed = signal.savgol_filter(raw,wl,p)\n",
    "    return smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot the original data in green and the smoothed data in red.\n",
    "# You can call plt twice in the same cell to plot the lines on the\n",
    "# same canvas. \n",
    "\n",
    "smoothed = smooth_sgf(data_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another method that is more useful for examining trends\n",
    "# than removing noise, is to use linear regression to plot\n",
    "# a line.\n",
    "\n",
    "# We'll use the Polynomial package from NumPy\n",
    "# https://numpy.org/doc/stable/reference/routines.polynomials.html\n",
    "from numpy.polynomial import Polynomial\n",
    "\n",
    "# We can use linear regression to fit our data to a straight line\n",
    "# this line will give us a sense of the trend of the data.\n",
    "\n",
    "def fit_regression(x, y):\n",
    "    \n",
    "    # this looks confusing because we are only using one of the\n",
    "    # returned objects from the Polynomial operations, the coefficents. \n",
    "    fit = Polynomial(Polynomial.fit(x,y,1).convert().coef).coef\n",
    "    \n",
    "    # we obtain the angle of coefficient fit[1] and the intercept fit[0]\n",
    "    return fit[1]* x + fit[0]\n",
    "\n",
    "# first plot your data as a line graph in green\n",
    "# then plot your x data with y the output of fit_regression in red"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In _Distant Horizons_, Ted Underwood describes the Stanford \"hard\" seeds lexicon as\n",
    "# a method of looking at concrete and abstract concepts over time.\n",
    "# He made the Stanford seeds available as a CSV file. \n",
    "\n",
    "seeds=list()\n",
    "ln = 0\n",
    "# Now we open the CSV file and read each line, appending to the metadata list:\n",
    "with open('shared/ENGL64.05-22F/lexicons/stanford_seeds.csv', encoding = 'utf-8') as f:\n",
    "    reader = csv.reader(f, delimiter = ',')\n",
    "    for row in reader:\n",
    "        seeds.append(row)        \n",
    "        # increment our counter\n",
    "        ln += 1\n",
    "# tell us how many entries we've read\n",
    "print(\"read %s lines\" % ln)\n",
    "\n",
    "# Let's remove the header (our \"metadata\") for easier processing:\n",
    "seeds = seeds[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the list to a dictionary for easy look-up\n",
    "stanford_seeds = dict()\n",
    "for word in seeds:\n",
    "    stanford_seeds[word[0]] = word[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stanford_seeds['jumping']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's open a sample file and look at a sample sentence\n",
    "sample = metadata.iloc[290]['Filename'].replace('xml','txt')\n",
    "\n",
    "# display this text\n",
    "print(metadata.iloc[290])\n",
    "\n",
    "import os.path\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "print(\"Opening\",os.path.basename(sample),\"...\")\n",
    "raw_text = open(\"shared/ENGL64.05-22F/data/na-slave-narratives/data/texts/\" + sample).read()\n",
    "tokens = word_tokenize(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many hard and abstract seed words in this section?\n",
    "\n",
    "# create dictionary and intialize  values\n",
    "seeds_count = dict()\n",
    "for k in set(stanford_seeds.values()):\n",
    "    seeds_count[k] = 0\n",
    "\n",
    "for token in tokens[1000:2000]:\n",
    "    if token in stanford_seeds.keys():\n",
    "        value =  stanford_seeds[token]\n",
    "        seeds_count[value] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use matplotlib to display the\n",
    "# total tokens\n",
    "# hard seeds\n",
    "# abstract seeds\n",
    "# for this 1,000 token segment of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now try to operate on/visualize all the 1,000 token segments of this book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, (if you have time) within the limitations of this dataset, how do we see \n",
    "# the distributions of hard and abstract seeds changing over time?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
