{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Cultural Analytics: Homework #4</h1></center>\n",
    "<center><h2>ENGL 64.05 / QSS 30.16, 22F</h2></center>\n",
    "<br>\n",
    "<center><b>Due</b> 11:59PM 11/01/2022</center>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import statistics\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Bing Sentiment  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Bing sentiment lexicons for positive and negative words\n",
    "with open('shared/ENGL64.05-22F/lexicons/bing_positive-words.txt') as fp:\n",
    "    bing_positive = fp.read().splitlines() \n",
    "\n",
    "with open('shared/ENGL64.05-22F/lexicons/bing_negative-words.txt') as fp:\n",
    "    bing_negative = fp.read().splitlines() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give a count of terms\n",
    "print(\"Found {0} negative terms\".format(len(bing_negative)))\n",
    "print(\"Found {0} positive terms\".format(len(bing_positive)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><font color=\"red\">Complete the function</font></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to assess orientation of sample text\n",
    "#\n",
    "# this function should return 'neutral', 'positive', or 'negative'\n",
    "# for the entire supplied text\n",
    "\n",
    "def sentiment_orientation(text):\n",
    "    \n",
    "    # determine if we need to tokenize or not\n",
    "    if type(text) == str:\n",
    "        # tokenize string\n",
    "        text = word_tokenize(text)\n",
    "    \n",
    "    # You'll need to iterate through the text variable (it should be a list) and check to \n",
    "    # see if the word is positive or negative and then assign a sentiment orientation \n",
    "    # based on a total score.\n",
    "    \n",
    "    return(orientation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now evaluate a sample product/film/book review that you found on the Web\n",
    "review = \"\"\"PASTE REVIEW CONTENTS HERE\n",
    "\"\"\"\n",
    "# this should display either positive, neutral, or negative\n",
    "print(sentiment_orientation(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and Convert Hawthorne's The Scarlet Letter into 100 Units\n",
    "input_text = \"shared/ENGL64.05-22F/data/Novel450/EN_1850_Hawthorne,Nathaniel_TheScarletLetter_Novel.txt\"\n",
    "\n",
    "# make into a collection of 100 documents\n",
    "raw_text = open(input_text).read()\n",
    "tokens = word_tokenize(raw_text)\n",
    "segment_length =  int(len(tokens)/100)\n",
    "segments = list()\n",
    "\n",
    "for i in range(100):\n",
    "        segment = tokens[segment_length*i:segment_length*(i+1)]\n",
    "        segments.append(' '.join(segment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><font color=\"red\">Complete the function</font></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to determine the mean sentiment of supplied text\n",
    "# this should return the mean sentiment using the Bing lexicon\n",
    "#\n",
    "\n",
    "def sentiment_means(text):\n",
    "    \n",
    "    # determine if we need to tokenize or not\n",
    "    if type(text) == str:\n",
    "        # tokenize string\n",
    "        text = word_tokenize(text)\n",
    "    \n",
    "    # HINT:\n",
    "    # we've imported the statistics package, which contains a function called 'mean'\n",
    "    # that will return the mean of a list of values.\n",
    "    # \n",
    "\n",
    "    return(mean_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain mean sentiment value for each segment\n",
    "sentiment_data = list()\n",
    "for segment in segments:\n",
    "    sentiment_data.append(sentiment_means(segment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to rescale these values from -1 to 1 using the following\n",
    "# function:\n",
    "\n",
    "def rescale(values):\n",
    "    scaled = 2 * (values - min(values))/( max(values) - min(values)) -1\n",
    "    return(scaled)\n",
    "\n",
    "# we can convert our list to a numpy array and then perform a vector operation\n",
    "# on all the data to scale it.\n",
    "data = np.asarray(sentiment_data)\n",
    "scaled = rescale(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot your extracted data:\n",
    "# - label x and y axis\n",
    "# - give it a title\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Question 1:</b> How well does the Bing lexicon work for sentiment scoring? What did you discover in your examination of sentiment in Hawthorne's novel?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: labMT Sentiment  \n",
    "\n",
    "This section uses the average scores from the labMT dataset. We'll first examine the dictionary and ask some questions about it before comparing this dictionary to the Bing lexicon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll load the CSV file and put everything into a Python dictionary\n",
    "import csv\n",
    "labMT_sentiment = dict()\n",
    "with open('shared/ENGL64.05-22F/lexicons/word_sentiment_scores.csv', encoding = 'utf-8') as f:\n",
    "    reader = csv.reader(f, delimiter = ',')\n",
    "    for row in reader:\n",
    "        labMT_sentiment[row[0]] = float(row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many words?\n",
    "print(\"found {0} words in labMT lexicon\".format(len(labMT_sentiment)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the top ten happiest words and their scores?\n",
    "for w in sorted(labMT_sentiment, key=labMT_sentiment.__getitem__,reverse=True)[:10]:\n",
    "    print(w,labMT_sentiment[w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are top ten least happiest words and their scores?\n",
    "for w in sorted(labMT_sentiment, key=labMT_sentiment.__getitem__)[:10]:\n",
    "    print(w,labMT_sentiment[w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"max sentiment\",max(labMT_sentiment.values()))\n",
    "print(\"min sentiment\",min(labMT_sentiment.values()))\n",
    "print(\"median sentiment\",statistics.median(labMT_sentiment.values()))\n",
    "print(\"mean sentiment\",statistics.mean(labMT_sentiment.values()))\n",
    "print(\"mode sentiment\",statistics.mode(labMT_sentiment.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract words scored as the mode and display\n",
    "mode_score = statistics.mode(labMT_sentiment.values())\n",
    "[x for x in labMT_sentiment if labMT_sentiment[x] == mode_score ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Question #2:</b> What do you make of these scores and these terms? Do you feel this is an appropriate range of words and scores? For what purposes? What do you make of the \"neutral\" words? What problems or limitations might you identify in using this lexicon for cultural analytics?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Scoring Texts with labMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to determine the mean sentiment of supplied text\n",
    "# this should return the mean sentiment using the labMT lexicon\n",
    "#\n",
    "\n",
    "def labMT_sentiment_means(text):\n",
    "    \n",
    "    # determine if we need to tokenize or not\n",
    "    if type(text) == str:\n",
    "        # tokenize string\n",
    "        text = word_tokenize(text)\n",
    "\n",
    "    # You should store your mean sentiment score for the text as mean_sentiment\n",
    "\n",
    "        \n",
    "    # HINT 1:\n",
    "    # we've imported the numpy package as np, which contains a function called 'mean' (thus 'np.mean')\n",
    "    # that will return the mean of a list of values.\n",
    "    # \n",
    "    \n",
    "    # HINT 2:\n",
    "    # You can easily check if a word exists in a dictionary with an 'if' statement\n",
    "    # if word in dictionary:\n",
    "    #     value = dictionary[word]\n",
    "    #\n",
    "    \n",
    "    # HINT 3:\n",
    "    # You should return '0' if there are no sentiment-bearing tokens in your segment of text  \n",
    "    \n",
    "    return mean_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from htrc_features import FeatureReader  \n",
    "\n",
    "def get_htrc_page_data(document):\n",
    "    fr = FeatureReader([document])\n",
    "    vol = next(fr.volumes())\n",
    "    ptc = vol.tokenlist(pos=False, case=False).reset_index().drop(['section'], axis=1)\n",
    "    page_list = set(ptc['page'])\n",
    "    \n",
    "    # extract tokens by page \n",
    "    tokens=list()\n",
    "    for page in page_list:\n",
    "        page_data = str()\n",
    "        \n",
    "        # operate on each token\n",
    "        for page_tokens in ptc.loc[ptc['page'] == page].iterrows():\n",
    "            if page_tokens[1][1].isalpha():\n",
    "                \n",
    "                # deal with frequency count by creating correct number of tokens\n",
    "                page_data += (' '.join([page_tokens[1][1]] * page_tokens[1][2])) + \" \"\n",
    "\n",
    "        tokens.append(page_data.split())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert a HathiTrust ID for a text here:\n",
    "page_data = get_htrc_page_data(\"\")\n",
    "\n",
    "# score using your labMT_sentiment_means function\n",
    "sentiment_scores = [labMT_sentiment_means(page) for page in page_data if len(page) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot your extracted data:\n",
    "# - label x and y axis\n",
    "# - give it a title\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(sentiment_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Question 3:</b> Compare the results of the mean scores for both the Bing and labMT sentiment lexicon (by altering the function call above in the line performing list comprehension and assigning a value to sentiment_scores). What other techniques might you use to calculate sentiment scores with these lexicons? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Scoring Texts with NRC Emotion Intensities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will load the NRC lexicon into a dictionary\n",
    "nrc_sentiment = dict()\n",
    "with open('shared/ENGL64.05-22F/lexicons/NRC-English-Emotion-Intensity-Lexicon-v1.txt', encoding = 'utf-8') as f:\n",
    "    reader = csv.reader(f, delimiter = '\\t')\n",
    "    for i, row in enumerate(reader):\n",
    "        # drop first row\n",
    "        if i != 0:\n",
    "            tmp = dict()\n",
    "            tmp['category'] = row[1]\n",
    "            tmp['score'] = float(row[2])\n",
    "            nrc_sentiment[row[0]] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell you will need to:\n",
    "# 1) read a sample text 2) tokenize the text 3) convert to lowercase \n",
    "# and 4) add each word within in the text that is in the NRC lexicon\n",
    "# to a list (that you will need to create) named 'sentiments'. \n",
    "#\n",
    "# You will most likely only want to examine 1,000 or 2,000 words. Perhaps\n",
    "# try some public-facing statement, a news article, or opinion essay?\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in list(set([nrc_sentiment[c]['category'] for c in nrc_sentiment])):\n",
    "    category_terms = [w for w in sentiments if nrc_sentiment[w]['category'] == category]\n",
    "    # fancy printing\n",
    "    print(\"\\033[1m{0}\\033[0m ({1}): {2}\".format(category, \n",
    "                                  len(category_terms), \n",
    "                                  ' '.join(category_terms)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Question 4:</b> How do these emotional categories change your interpretation of the sentiment of your selected text? Do you feel these categories are an improvement over binary (positive/negative) or scaled (i.e., labMT) sentiment? What questions do you have about this lexicon?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
